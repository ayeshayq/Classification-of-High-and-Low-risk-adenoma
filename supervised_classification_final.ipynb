{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65bce50-aa72-4a68-aa1c-a78c4a57f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 1 — PROJECT SETUP, Libraries, Dependies and Data loading\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "Goal:\n",
    "1. This notebook investigates whether volatile organic compounds (VOCs)\n",
    "measured in breath can differentiate high-risk (HRA) and low-risk (LRA)\n",
    "individuals in the FORAGI dataset.\n",
    "2. This first section ensures reproducibility and loads the dataset\n",
    "cleanly with consistent missing-value handling.\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================\n",
    "# Core Libraries & Dependencies\n",
    "# ============================================================\n",
    "# If you're running this on a clean machine (like a new setup or shared laptop):\n",
    "# !pip install numpy pandas matplotlib seaborn scipy scikit-learn xgboost shap openpyxl --quiet\n",
    "\n",
    "# --- Core ---\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Visualization ---\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Statistical tests ---\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# --- Machine Learning ---\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    roc_curve,\n",
    "    auc\n",
    ")\n",
    "\n",
    "# --- XGBoost ---\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# --- SHAP (Model interpretation) ---\n",
    "# Install only if not already present\n",
    "try:\n",
    "    import shap\n",
    "except ImportError:\n",
    "    !pip install shap --quiet\n",
    "    import shap\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Reproducibility \n",
    "# ============================================================\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "\n",
    "# Load dataset \n",
    "filename = \"path/to/your/file.xlsx \"\n",
    "\n",
    "# Make sure the file exists before reading\n",
    "if not os.path.exists(filename):\n",
    "    raise FileNotFoundError(f\"❌ File not found at: {filename}\\nPlease check the path and try again.\")\n",
    "\n",
    "# Read Excel file & treat common NA labels as missing\n",
    "df = pd.read_excel(\n",
    "    filename,\n",
    "    engine=\"openpyxl\",\n",
    "    na_values=[\"n.a.\", \"N.A.\", \"NA\", \"na\", \"NaN\", \"\"]\n",
    ")\n",
    "\n",
    "print(f\" Loaded file: {filename}\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "\n",
    "# Show a preview\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c2f998-1b8b-4629-a3f2-79793506f566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 2 — Cleaning and organising data \n",
    "# ============================================================\n",
    "\"\"\"\n",
    "Goal:\n",
    "This section standardizes labels and prepares subgroup identifiers\n",
    "so that blanks and biological samples can be processed consistently.\n",
    "It also calculates missingness per subgroup to evaluate data quality.\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================\n",
    "#Cleaning\n",
    "# ============================================================\n",
    "\n",
    "# Replace Study subgroup for blanks based on Label for easier coding later on\n",
    "# 'EquipmentBlank' and 'AmbientBlank' are technical control samples.\n",
    "# Recode them numerically to simplify downstream filtering and grouping.\n",
    "df.loc[df[\"Label\"] == \"EquipmentBlank\", \"Study subgroup\"] = 0\n",
    "df.loc[df[\"Label\"] == \"AmbientBlank\", \"Study subgroup\"] = 1\n",
    "\n",
    "# Remove rows where Study subgroup is \"NOT FOUND\"\n",
    "df = df[df[\"Study subgroup\"] != \"NOT FOUND\"]\n",
    "\n",
    "# Ensure the subgroup column is numeric (important for modeling)\n",
    "df[\"Study subgroup\"] = pd.to_numeric(df[\"Study subgroup\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Optional: check counts\n",
    "print(\" Current Study subgroup counts:\")\n",
    "print(df[\"Study subgroup\"].value_counts(dropna=False))\n",
    "\n",
    "\n",
    "# Find metabolite columns dynamically\n",
    "try:\n",
    "    metabolite_start_col = df.columns.get_loc(\"2-Pentene, (Z)\")\n",
    "except KeyError:\n",
    "    raise KeyError(\"Column '2-Pentene, (Z)' not found — check your Excel column names.\")\n",
    "\n",
    "metabolite_cols = df.columns[metabolite_start_col:]\n",
    "\n",
    "# Keep a copy of all rows (including blanks)\n",
    "df_samples = df.copy()\n",
    "\n",
    "# And one for real samples only (subgroups 2 & 3)\n",
    "real_mask = df_samples[\"Study subgroup\"].isin([2, 3])\n",
    "\n",
    "# ============================================================\n",
    "# Calculating missingness\n",
    "# ============================================================\n",
    "\n",
    "missing_summary = {}\n",
    "for subgroup in [2, 3]:\n",
    "    subgroup_df = df_samples[df_samples[\"Study subgroup\"] == subgroup]\n",
    "    missing_count = subgroup_df[metabolite_cols].isna().sum()\n",
    "    missing_percentage = subgroup_df[metabolite_cols].isna().mean() * 100\n",
    "    missing_summary[subgroup] = pd.DataFrame({\n",
    "        \"Missing Count\": missing_count,\n",
    "        \"Missing Percentage\": missing_percentage\n",
    "    })\n",
    "\n",
    "# Display summaries\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "print(\"Missingness for Study Subgroup 2 (High-risk?):\")\n",
    "print(missing_summary[2].head(10))\n",
    "\n",
    "print(\"Missingness for Study Subgroup 3 (Low-risk?):\")\n",
    "print(missing_summary[3].head(10))\n",
    "\n",
    "# Save corrected file if you want \n",
    "# -----------------------------\n",
    "#os.makedirs(\"results\", exist_ok=True)\n",
    "#output_path = os.path.join(\"results\", \"FORAGI_checked_blanks.xlsx\")\n",
    "#df.to_excel(output_path, index=False)\n",
    "\n",
    "# print(f\"Cleaned file saved at: {os.path.abspath(output_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cdc452-698a-434b-96c8-f6158be2ce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 3 — Splitting Trand and test and organising our metadata\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "Goal:\n",
    "To prepare a clean and reproducible dataset for downstream analysis.\n",
    "We first isolate real biological samples (subgroups 2 & 3),\n",
    "then perform a stratified train/test split to preserve class balance.\n",
    "Finally, we separate metadata from metabolite (VOC) features.\n",
    "\"\"\"\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Keep only real biological samples (subgroups 2 & 3)\n",
    "#\n",
    "df_real = df[df[\"Study subgroup\"].isin([2, 3])].copy()\n",
    "\n",
    "print(f\"Real samples shape: {df_real.shape}\")\n",
    "print(df_real[\"Study subgroup\"].value_counts(dropna=False))\n",
    "\n",
    "# ============================================================\n",
    "#Stratified Train/Test Split (80/20)\n",
    "# ============================================================\n",
    "#Stratification ensures the class balance (HRA vs LRA) is preserved in both splits.\n",
    "train_idx, test_idx = train_test_split(\n",
    "    df_real.index,\n",
    "    test_size=0.2,\n",
    "    stratify=df_real[\"Study subgroup\"],\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "#Create train and test sets\n",
    "df_train = df_real.loc[train_idx].copy()\n",
    "df_test = df_real.loc[test_idx].copy()\n",
    "\n",
    "print(\"Train size: {df_train.shape[0]}, Test size: {df_test.shape[0]}\")\n",
    "\n",
    "\n",
    "# Identify metadata columns\n",
    "# Metadata columns include demographics and sampling info (e.g., Age, Sex, Site).\n",
    "# The VOC features start from the column '2-Pentene, (Z)', located earlier\n",
    "metadata_cols = df_train.columns[:metabolite_start_col]\n",
    "\n",
    "print(\"Number of metadata columns: {len(metadata_cols)}\")\n",
    "print(\"Metadata columns:\")\n",
    "print(list(metadata_cols))\n",
    "\n",
    "\n",
    "#Split metadata and VOCs\n",
    "# -----------------------------\n",
    "df_train_metadata = df_train[metadata_cols].copy()\n",
    "df_test_metadata = df_test[metadata_cols].copy()\n",
    "\n",
    "print(\"Metadata split complete.\")\n",
    "print(f\"Train metadata shape: {df_train_metadata.shape}\")\n",
    "print(f\"Test metadata shape: {df_test_metadata.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e138060e-c3b1-4bff-81dd-98bc523908d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 4 — Filter missingness and impute\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "Goal:\n",
    "In this section we want to remove VOCs with too much missing data to ensure reliable statistical modeling and impute missing entries.\n",
    "Strategy:\n",
    "1. Remove features (VOCs) with >30% missing values in BOTH subgroups.\n",
    "2. If a VOC is missing >30% in one subgroup :  it is retained, but that subgroup's \n",
    "   missing values are imputed using the opposite subgroup's median.\n",
    "3. If a VOC is missing >30%, use the subgroup's median to impute missing entries. \n",
    "Why the median?\n",
    "Because VOC values are often skewed or contain extreme outliers.\n",
    "The mean can be heavily influenced by a few large measurements\n",
    "The median reflects the central tendency of the majority of samples so it is more rubust.\n",
    "4. Apply the same imputation logic to the test set using training medians\n",
    "   (avoiding data leakage).\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Reproducibility \n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "# Threshold (% missing allowed per subgroup)\n",
    "threshold = 30  # max allowed % missing per subgroup\n",
    "cols_to_keep = []\n",
    "\n",
    "df_train = df_train.copy()\n",
    "df_test = df_test.copy()\n",
    "\n",
    "#Handle missingness and define 'cols_to_keep'\n",
    "for col in metabolite_cols:\n",
    "    # % missing per subgroup\n",
    "    pct2 = df_train.loc[df_train[\"Study subgroup\"] == 2, col].isna().mean() * 100\n",
    "    pct3 = df_train.loc[df_train[\"Study subgroup\"] == 3, col].isna().mean() * 100\n",
    "\n",
    "    # Skip VOCs missing too much in both subgroups\n",
    "    if pct2 > threshold and pct3 > threshold:\n",
    "        continue\n",
    "\n",
    "    cols_to_keep.append(col)\n",
    "\n",
    "    # Impute using subgroup medians\n",
    "    med2 = df_train.loc[df_train[\"Study subgroup\"] == 2, col].median()\n",
    "    med3 = df_train.loc[df_train[\"Study subgroup\"] == 3, col].median()\n",
    "\n",
    "    # Fill subgroup 2\n",
    "    df_train.loc[df_train[\"Study subgroup\"] == 2, col] = (\n",
    "        df_train.loc[df_train[\"Study subgroup\"] == 2, col]\n",
    "        .fillna(med2 if pct2 <= threshold else med3)\n",
    "    )\n",
    "\n",
    "    # Fill subgroup 3\n",
    "    df_train.loc[df_train[\"Study subgroup\"] == 3, col] = (\n",
    "        df_train.loc[df_train[\"Study subgroup\"] == 3, col]\n",
    "        .fillna(med3 if pct3 <= threshold else med2)\n",
    "    )\n",
    "\n",
    "#Apply same logic to test set (using train medians)\n",
    "for col in cols_to_keep:\n",
    "    med2 = df_train.loc[df_train[\"Study subgroup\"] == 2, col].median()\n",
    "    med3 = df_train.loc[df_train[\"Study subgroup\"] == 3, col].median()\n",
    "    for grp, med in [(2, med2), (3, med3)]:\n",
    "        mask = df_test[\"Study subgroup\"] == grp\n",
    "        df_test.loc[mask, col] = df_test.loc[mask, col].fillna(med)\n",
    "\n",
    "#Combine metadata + VOCs for modeling\n",
    "df_train_vocs = df_train[cols_to_keep].copy()\n",
    "df_test_vocs = df_test[cols_to_keep].copy()\n",
    "\n",
    "X_train = pd.concat([df_train_metadata, df_train_vocs], axis=1)\n",
    "X_test = pd.concat([df_test_metadata, df_test_vocs], axis=1)\n",
    "\n",
    "y_train = df_train[\"Study subgroup\"].astype(int)\n",
    "y_test = df_test[\"Study subgroup\"].astype(int)\n",
    "\n",
    "# Some checks\n",
    "# -----------------------------\n",
    "print(f\"Number of VOCs kept: {len(cols_to_keep)}\")\n",
    "print(f\"Training samples: {len(df_train)} | Test samples: {len(df_test)}\")\n",
    "\n",
    "# Ensure alignment (no leakage)\n",
    "assert X_train.index.equals(df_train.index)\n",
    "assert X_test.index.equals(df_test.index)\n",
    "print(\"Train/test data prepared correctly with no leakage or randomness.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac7b472-d347-4abe-8cce-7c3eb80674d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 5 - Selecting VOCs using non-parametrric test : Mann–Whitney U Test\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "Goal:\n",
    "1. Identify VOCs that significantly differ between real biological samples (subgroups 2 & 3)\n",
    "and blanks (0 = EquipmentBlank, 1 = AmbientBlank) and remove those that don't.\n",
    "Why? To filter out compounds likely arising from the environment or instrument.\n",
    "Why Mann–Whitney? because it is a non-parametric alternative to the t-test so it doesn't assume normality,\n",
    "this is ideal for VOC intensity data, which are typically right-skewed.\n",
    "Why no FDR correction? \n",
    "FDR correction was not applied because with a small sample size it would over-correct and remove true biological signals.\n",
    "Also this is more \"exploratory\".\n",
    "\n",
    "\"\"\"\n",
    "# --- Reproducibility ---\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Step 1 — Include blanks for comparison (0 = EquipmentBlank, 1 = AmbientBlank)\n",
    "df.loc[df[\"Label\"].str.lower().str.contains(\"equipmentblank\"), \"Study subgroup\"] = 0\n",
    "df.loc[df[\"Label\"].str.lower().str.contains(\"ambientblank\"), \"Study subgroup\"] = 1\n",
    "\n",
    "df_blanks = df[df[\"Study subgroup\"].isin([0, 1])].copy()\n",
    "\n",
    "# Combine real biological samples (2, 3) with blanks\n",
    "df_train_for_test = pd.concat([df_train, df_blanks], axis=0).reset_index(drop=True)\n",
    "\n",
    "print(f\"Blanks shape: {df_blanks.shape}, Combined shape: {df_train_for_test.shape}\")\n",
    "\n",
    "#Step 2 — Select VOC columns to test\n",
    "# Keep only metabolite columns present in df_train\n",
    "metabolite_cols = [c for c in metabolite_cols if c in df_train.columns]\n",
    "\n",
    "print(f\"Testing {len(metabolite_cols)} VOCs for significance vs. blanks...\")\n",
    "\n",
    "# Mann–Whitney U test\n",
    "significant_vocs = []\n",
    "pvals = {}\n",
    "\n",
    "for col in metabolite_cols:\n",
    "    real_vals = df_train_for_test.loc[\n",
    "        df_train_for_test[\"Study subgroup\"].isin([2, 3]), col\n",
    "    ].dropna()\n",
    "\n",
    "    blank_vals = df_train_for_test.loc[\n",
    "        df_train_for_test[\"Study subgroup\"].isin([0, 1]), col\n",
    "    ].dropna()\n",
    "\n",
    "    # Skip columns with too few values\n",
    "    if len(real_vals) <= 2 or len(blank_vals) <= 2:\n",
    "        continue\n",
    "\n",
    "    stat, pval = mannwhitneyu(real_vals, blank_vals, alternative=\"two-sided\")\n",
    "    pvals[col] = pval\n",
    "\n",
    "    if pval < 0.05:\n",
    "        significant_vocs.append(col)\n",
    "\n",
    "#Filter train/test to keep only significant VOCs\n",
    "df_train_filtered = pd.concat(\n",
    "    [df_train[[\"Study subgroup\"]], df_train[significant_vocs]], axis=1\n",
    ")\n",
    "df_test_filtered = pd.concat(\n",
    "    [df_test[[\"Study subgroup\"]], df_test[significant_vocs]], axis=1\n",
    ")\n",
    "\n",
    "print(f\"Kept {len(significant_vocs)} significant VOCs out of {len(metabolite_cols)} tested.\")\n",
    "\n",
    "# Save results for inspection\n",
    "#os.makedirs(\"results\", exist_ok=True)\n",
    "#output_file = os.path.join(\"results\", \"significant_VOCs_train_test.xlsx\")\n",
    "\n",
    "#with pd.ExcelWriter(output_file, engine=\"openpyxl\") as writer:\n",
    "#    df_train_filtered.to_excel(writer, sheet_name=\"Train\", index=False)\n",
    "#    df_test_filtered.to_excel(writer, sheet_name=\"Test\", index=False)\n",
    "#    pd.DataFrame({\n",
    "#        \"VOC\": list(pvals.keys()),\n",
    "#        \"p-value\": list(pvals.values()),\n",
    "#        \"Significant (p<0.05)\": [col in significant_vocs for col in pvals.keys()]\n",
    "#    }).sort_values(by=\"p-value\").to_excel(writer, sheet_name=\"p_values\", index=False)\n",
    "#    pd.DataFrame({\n",
    "#        \"Set\": [\"Train\", \"Test\"],\n",
    "#        \"Remaining_VOCs\": [\n",
    "#            len(df_train_filtered.columns) - 1,\n",
    "#            len(df_test_filtered.columns) - 1,\n",
    "#        ],\n",
    "#    }).to_excel(writer, sheet_name=\"VOC_counts\", index=False)\n",
    "\n",
    "#print(f\"Significant VOC results saved to: {os.path.abspath(output_file)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82c96a2-bad8-4afb-a6be-4cee6ba4845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 6 — Visualising outliers using PCA and Locating them using Isolation Forest (IF)\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "Goal:\n",
    "1. To identify and visualize potential outliers in the training data that may represent \n",
    "technical artefacts.\n",
    "2. Use PCA for visualization \n",
    "3. Isolation Forest to identify and the remove them.\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================\n",
    "# PCA\n",
    "# ============================================================\n",
    "\n",
    "# Use only VOC features for outlier detection ---\n",
    "voc_train = df_train_filtered.drop(columns=[\"Study subgroup\"]).copy()\n",
    "\n",
    "# Handle NaNs before scaling \n",
    "voc_train = voc_train.apply(pd.to_numeric, errors=\"coerce\")\n",
    "voc_train.fillna(voc_train.mean(), inplace=True)\n",
    "\n",
    "# Standardize features \n",
    "# (important since PCA and IsolationForest are distance-based)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(voc_train)\n",
    "\n",
    "# PCA Visualization (before outlier removal)\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "pca_proj = pca.fit_transform(X_scaled)\n",
    "\n",
    "df_pca = pd.DataFrame({\n",
    "    \"PC1\": pca_proj[:, 0],\n",
    "    \"PC2\": pca_proj[:, 1],\n",
    "    \"Group\": df_train_filtered[\"Study subgroup\"].map({2: \"High Risk\", 3: \"Low Risk\"}).values\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.scatterplot(\n",
    "    data=df_pca,\n",
    "    x=\"PC1\", y=\"PC2\",\n",
    "    hue=\"Group\",\n",
    "    palette=[\"#E56B6F\", \"#6D597A\"],\n",
    "    s=80, edgecolor=\"black\", alpha=0.85\n",
    ")\n",
    "plt.title(\"PCA Projection of VOCs (Before Outlier Removal)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# ============================================================\n",
    "# Isolation Forest\n",
    "# ============================================================\n",
    "# Isolation Forest isolates anomalies by randomly partitioning data points;\n",
    "# points that require fewer splits to isolate are considered outliers.\n",
    "iso = IsolationForest(\n",
    "    n_estimators=300,\n",
    "    contamination=0.05,  # ≈5% expected outliers\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "outlier_flags = iso.fit_predict(X_scaled)\n",
    "df_train_filtered = df_train_filtered.copy()  # avoid SettingWithCopyWarning\n",
    "df_train_filtered[\"OutlierFlag\"] = np.where(outlier_flags == -1, \"Outlier\", \"Inlier\")\n",
    "\n",
    "# Add to PCA DataFrame for visualization\n",
    "df_pca[\"OutlierFlag\"] = df_train_filtered[\"OutlierFlag\"].values\n",
    "\n",
    "# Visualize detected outliers\n",
    "# -----------------------------\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.scatterplot(\n",
    "    data=df_pca,\n",
    "    x=\"PC1\", y=\"PC2\",\n",
    "    hue=\"OutlierFlag\",\n",
    "    palette={\"Inlier\": \"#4CAF50\", \"Outlier\": \"#E63946\"},\n",
    "    s=80, edgecolor=\"black\", alpha=0.85\n",
    ")\n",
    "plt.title(\"Isolation Forest Outlier Detection (PCA Projection)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary\n",
    "# -----------------------------\n",
    "n_outliers = (df_train_filtered[\"OutlierFlag\"] == \"Outlier\").sum()\n",
    "print(f\" Detected {n_outliers} potential outliers out of {len(df_train_filtered)} samples.\")\n",
    "\n",
    "# preview flagged samples\n",
    "df_train_filtered[df_train_filtered[\"OutlierFlag\"] == \"Outlier\"].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4524acc-e059-4e4a-9e72-ebede318581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 7 — Remove outliers and clean data \n",
    "# ============================================================\n",
    "\"\"\"\n",
    "Goal:\n",
    "1. Remove samples identified as statistical outliers by the Isolation Forest\n",
    "to ensure that the rest of the analysis is not affected.\n",
    "note: \n",
    "a. some distant samples in PCA were classified as inliers by IF but these were kept because PCA only shows two principal components\n",
    "and these samples may behave normally in the full multidimensional VOC space.\n",
    "b. why was IF not repeated a second time to ensure there's not more outliers? Because this check already removes the very extreme outliers,\n",
    "the other ones it detects (not shown in notebook) are not as extreme as the current ones. These less extreme outliers are interesting to \n",
    "keep because they may reflect true biology (again VOC range a lot). The main goal was to remove outliers that were more likely artifacts.\n",
    "\n",
    "\"\"\"\n",
    "#remove outliers before training\n",
    "df_train_filtered_no_outliers = (\n",
    "    df_train_filtered[df_train_filtered[\"OutlierFlag\"] == \"Inlier\"]\n",
    "    .copy()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f\"Remaining after outlier removal: {df_train_filtered_no_outliers.shape[0]} samples\")\n",
    "\n",
    "#Check what proportion of samples were removed as outliers (should be close to 5%)\n",
    "outlier_ratio = 1 - (len(df_train_filtered_no_outliers) / len(df_train_filtered))\n",
    "print(f\" Outlier ratio removed: {outlier_ratio * 100:.2f}%\")\n",
    "\n",
    "# Check subgroup balance after outlier removal\n",
    "print(\"\\nSubgroup counts after outlier removal:\")\n",
    "print(df_train_filtered_no_outliers[\"Study subgroup\"].value_counts())\n",
    "\n",
    "\n",
    "# Drop the flag column (because its not needed for downstream analysis)\n",
    "df_train_filtered_no_outliers.drop(columns=[\"OutlierFlag\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Use this cleaned dataset for training\n",
    "df_train_filtered = df_train_filtered_no_outliers.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030083de-9a15-4488-9959-f44b716708de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 8 — RANDOM FOREST (RF)\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "Goal:\n",
    "1. Train a Random Forest model combining participant metadata and VOC features\n",
    "to classify study subgroups (High-risk = 2, Low-risk = 3).\n",
    "2. Upsampling is applied to balance the classes and avoid bias toward the majority group.\n",
    "How? Using bootstrapping. \n",
    "Why? because its a neat way to make groups comparable, keeps the original data distribution intact and is easier than SMOTE which\n",
    "synthetically generates samples and can add artificial variance.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# --- Prepare data ---\n",
    "df_rf_train = df_train_metadata.copy().reset_index(drop=True)\n",
    "df_rf_test = df_test_metadata.copy().reset_index(drop=True)\n",
    "df_train_filtered = df_train_filtered.reset_index(drop=True)\n",
    "df_test_filtered = df_test_filtered.reset_index(drop=True)\n",
    "\n",
    "# BMI does NOT exist but was computed as a measure from the Weight and Length\n",
    "for df_part in [df_rf_train, df_rf_test]:\n",
    "    if \"BMI\" not in df_part.columns:\n",
    "        df_part[\"BMI\"] = df_part.apply(\n",
    "            lambda r: r[\"Weight\"] / ((r[\"Length\"] / 100) ** 2)\n",
    "            if pd.notna(r[\"Weight\"]) and pd.notna(r[\"Length\"]) and r[\"Length\"] > 0\n",
    "            else np.nan,\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "# Combine metadata + VOCs\n",
    "# This metadata was chosen because 1)has no missing values 2)is most related to colorectal cancer \n",
    "#A safety check is included below to drop the 'OutlierFlag' column if present.\n",
    "for df_part in [df_rf_train, df_rf_test, df_train_filtered, df_test_filtered]:\n",
    "    if \"OutlierFlag\" in df_part.columns:\n",
    "        df_part.drop(columns=[\"OutlierFlag\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "meta_cols = [\"Sex\", \"Weight\", \"Length\", \"BMI\", \"Smoking status\", \"Alcohol\", \"Age\"]\n",
    "\n",
    "X_train_combined = pd.concat(\n",
    "    [df_rf_train[meta_cols], df_train_filtered.drop(columns=[\"Study subgroup\"])],\n",
    "    axis=1\n",
    ")\n",
    "X_test_combined = pd.concat(\n",
    "    [df_rf_test[meta_cols], df_test_filtered.drop(columns=[\"Study subgroup\"])],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Handle missing values (normally there's none)\n",
    "X_train_combined = X_train_combined.apply(pd.to_numeric, errors='coerce')\n",
    "X_test_combined = X_test_combined.apply(pd.to_numeric, errors='coerce')\n",
    "X_train_combined.fillna(X_train_combined.mean(), inplace=True)\n",
    "X_test_combined.fillna(X_train_combined.mean(), inplace=True)\n",
    "\n",
    "# Define target variables\n",
    "y_train = df_train_filtered[\"Study subgroup\"].astype(int)\n",
    "y_test = df_test_filtered[\"Study subgroup\"].astype(int)\n",
    "\n",
    "train_data = pd.concat([X_train_combined, y_train], axis=1)\n",
    "\n",
    "# Split by subgroup\n",
    "train_hr = train_data[train_data[\"Study subgroup\"] == 2]  # High-risk (minority)\n",
    "train_lr = train_data[train_data[\"Study subgroup\"] == 3]  # Low-risk (majority)\n",
    "\n",
    "# Upsample high-risk to match low-risk\n",
    "train_hr_upsampled = resample(\n",
    "    train_hr,\n",
    "    replace=True,\n",
    "    n_samples=len(train_lr),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "#Combine and shuffle to mix both classes evenly\n",
    "train_balanced = pd.concat([train_lr, train_hr_upsampled]).sample(frac=1, random_state=42)\n",
    "\n",
    "\n",
    "# Separate features and labels\n",
    "X_train_balanced = train_balanced.drop(columns=[\"Study subgroup\"])\n",
    "y_train_balanced = train_balanced[\"Study subgroup\"]\n",
    "\n",
    "print(\"\\nAfter balancing:\")\n",
    "print(y_train_balanced.value_counts())\n",
    "\n",
    "\n",
    "#Train Random Forest, this was tuned to avoid overffiting based on several runs (no hyperpamatre tuning though)\n",
    "rf_model_combined = RandomForestClassifier(\n",
    "    n_estimators=300,      # lower number to prevent overfitting\n",
    "    max_depth=8,           # limit tree depth\n",
    "    min_samples_leaf=5,    # force each leaf to have at least 5 samples\n",
    "    max_features='sqrt',   # add randomness to feature selection\n",
    "    oob_score=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model_combined.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "\n",
    "\n",
    "#Evaluate on test set\n",
    "\n",
    "y_pred = rf_model_combined.predict(X_test_combined)\n",
    "print(f\"\\nAccuracy (metadata + VOCs, upsampled): {accuracy_score(y_test, y_pred)*100:.2f}%\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "plt.title(\"Confusion Matrix — Random Forest (Upsampled Metadata + VOCs)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "#Feature Importances\n",
    "importances = pd.Series(rf_model_combined.feature_importances_, index=X_train_balanced.columns)\n",
    "top20 = importances.sort_values(ascending=False).head(20)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "top20.plot(kind=\"barh\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Top 20 Feature Importances (Upsampled Metadata + VOCs)\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b6f19b-72eb-4402-a04c-c5dd2182bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 9 — Evaluate the RF model \n",
    "# ============================================================\n",
    "\"\"\"\n",
    "Goal:\n",
    "1. To rigorously evaluate model performance using both internal validation\n",
    "(OOB score and cross-validation) and external validation (test set metrics).\n",
    "Why ? \n",
    "a. OOB is an internal validation in RF that uses the out of bag samples (samples not used by a tree during training) to test\n",
    "how well that tree predicts those. Its a way to evaluate the model without needing a seperate Cross validation. Of course, the results\n",
    "will be better than test because the data distribution stays the same as the training data.\n",
    "b. Cross validation is also used to further evaluate model performance. Ideally, the OOB, CV and test accuracy scores should not be too far \n",
    "off or it could suggest over or under fitting. \n",
    "2. Reported metrics : sensitivity, specificity, and precision-recall performance\n",
    "\"\"\"\n",
    "# OOB Accuracy\n",
    "if hasattr(rf_model_combined, \"oob_score_\"):\n",
    "    print(f\"OOB Accuracy: {rf_model_combined.oob_score_ * 100:.2f}%\")\n",
    "\n",
    "# Cross-validation Accuracy (5 folds)\n",
    "cv_scores = cross_val_score(rf_model_combined, X_train_balanced, y_train_balanced, cv=5)\n",
    "print(f\"CV Accuracy: {cv_scores.mean() * 100:.2f}% ± {cv_scores.std() * 100:.2f}%\")\n",
    "\n",
    "#Sensitivity, Specificity, and Precision–Recall Curve\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[2, 3])\n",
    "tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (np.nan, np.nan, np.nan, np.nan)\n",
    "\n",
    "# Compute metrics \n",
    "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else np.nan  # Recall for HR\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else np.nan  # Recall for LR\n",
    "precision = precision_score(y_test, y_pred, pos_label=2)\n",
    "recall = recall_score(y_test, y_pred, pos_label=2)\n",
    "\n",
    "print(\"\\n Detailed Performance Metrics (Test Set):\")\n",
    "print(f\"Sensitivity (Recall for High-Risk): {sensitivity:.3f}\")\n",
    "print(f\"Specificity (Recall for Low-Risk): {specificity:.3f}\")\n",
    "print(f\"Precision (High-Risk): {precision:.3f}\")\n",
    "print(f\"Recall (High-Risk): {recall:.3f}\")\n",
    "\n",
    "# Precision–Recall curve (for test set) \n",
    "y_score = rf_model_combined.predict_proba(X_test_combined)[:, list(rf_model_combined.classes_).index(2)]\n",
    "prec, rec, _ = precision_recall_curve(y_test, y_score, pos_label=2)\n",
    "ap = average_precision_score(y_test, y_score, pos_label=2)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(rec, prec, color=\"purple\", linewidth=2)\n",
    "plt.fill_between(rec, prec, alpha=0.2, color=\"purple\")\n",
    "plt.title(f\"Precision–Recall Curve (Test Set)\\nAP = {ap:.3f}\")\n",
    "plt.xlabel(\"Recall (Sensitivity)\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#OOB Precision–Recall Estimate\n",
    "if hasattr(rf_model_combined, \"oob_decision_function_\"):\n",
    "    try:\n",
    "        y_score_oob = rf_model_combined.oob_decision_function_[:, list(rf_model_combined.classes_).index(2)]\n",
    "        prec_oob, rec_oob, _ = precision_recall_curve(y_train_balanced, y_score_oob, pos_label=2)\n",
    "        ap_oob = average_precision_score(y_train_balanced, y_score_oob, pos_label=2)\n",
    "        \n",
    "        plt.figure(figsize=(6, 5))\n",
    "        plt.plot(rec_oob, prec_oob, color=\"teal\", linewidth=2)\n",
    "        plt.fill_between(rec_oob, prec_oob, alpha=0.2, color=\"teal\")\n",
    "        plt.title(f\"Precision–Recall Curve (OOB Estimate)\\nAP = {ap_oob:.3f}\")\n",
    "        plt.xlabel(\"Recall (Sensitivity)\")\n",
    "        plt.ylabel(\"Precision\")\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not compute OOB PR curve: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba2707-da74-4a25-a3ca-089154a440c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 10 — XGBOOST CLASSIFIER\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "Goal:\n",
    "1. Train and evaluate a reproducible XGBoost model using both metadata and VOC features\n",
    "to classify participants as High-risk (1) or Low-risk (0).\n",
    "2. Parametre choices : These parameters were chosen to make the model stable, interpretable, and reproducible.\n",
    "A lower learning rate and moderate depth was used to reduce overfitting, \n",
    "stochastic sampling was desabled (subsample=1.0, colsample_bytree=1.0) to ensure that repeated runs yield identical results.\n",
    "3. Parallel computing: n_jobs = 1 was used because it uses the same model in every run. \n",
    "if n_jobs > 1 was used then it would be faster and use parallel threads but not always reproducible (the exact results) \n",
    "cause the combining of results could happen in a different order each time leading to different resutls.\n",
    "\n",
    "Why XGBoost?\n",
    "It’s a gradient boosting algorithm that builds decision trees sequentially,\n",
    "each correcting errors made by the previous one. It’s generally more powerful and less biased\n",
    "than standard Random Forests.\n",
    "\n",
    "Key additions:\n",
    "1. Full reproducibility (fixed seeds, single-threaded).\n",
    "2. Deterministic configuration (no random sampling).\n",
    "3. Binary classification setup with HR=1 and LR=0.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# GLOBAL REPRODUCIBILITY LOCK\n",
    "SEED = 42\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "xgb.set_config(verbosity=0)\n",
    "\n",
    "print(\"Global random seeds fixed for reproducibility.\")\n",
    "\n",
    "#Prepare Data\n",
    "X_train_xgb = X_train_balanced.copy(deep=True)\n",
    "X_test_xgb = X_test_combined.copy(deep=True)\n",
    "y_train_xgb = y_train_balanced.copy(deep=True)\n",
    "y_test_xgb = y_test.copy(deep=True)\n",
    "\n",
    "# Recode classes: 2 = High-risk → 1, 3 = Low-risk → 0\n",
    "y_train_xgb = y_train_xgb.replace({2: 1, 3: 0})\n",
    "y_test_xgb = y_test_xgb.replace({2: 1, 3: 0})\n",
    "\n",
    "print(f\"Train shape: {X_train_xgb.shape}, Test shape: {X_test_xgb.shape}\")\n",
    "print(\"Label distribution (train):\")\n",
    "print(y_train_xgb.value_counts())\n",
    "\n",
    "#Train XGBoost (deterministic setup)\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    subsample=1.0,            # full sampling for reproducibility\n",
    "    colsample_bytree=1.0,     # full column sampling\n",
    "    random_state=SEED,\n",
    "    scale_pos_weight=1,\n",
    "    eval_metric=\"logloss\",\n",
    "    objective=\"binary:logistic\",\n",
    "    use_label_encoder=False,\n",
    "    n_jobs=1                  # single-thread for fully deterministic results\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train_xgb, y_train_xgb)\n",
    "print(\"XGBoost model trained successfully.\")\n",
    "\n",
    "#Evaluate\n",
    "y_pred_xgb = xgb_model.predict(X_test_xgb)\n",
    "y_proba_xgb = xgb_model.predict_proba(X_test_xgb)[:, 1]\n",
    "\n",
    "acc = accuracy_score(y_test_xgb, y_pred_xgb)\n",
    "print(f\"\\n Test Accuracy: {acc*100:.2f}%\")\n",
    "print(classification_report(\n",
    "    y_test_xgb, y_pred_xgb,\n",
    "    target_names=[\"Low-risk (0)\", \"High-risk (1)\"],\n",
    "    digits=3\n",
    "))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_xgb, y_pred_xgb, labels=[0, 1])\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Purples\",\n",
    "            xticklabels=[\"Pred: LR\", \"Pred: HR\"],\n",
    "            yticklabels=[\"True: LR\", \"True: HR\"])\n",
    "plt.title(\"Confusion Matrix — XGBoost (Metadata + VOCs, HR=1)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Metrics & Curves\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else np.nan\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else np.nan\n",
    "precision_val = precision_score(y_test_xgb, y_pred_xgb)\n",
    "recall_val = recall_score(y_test_xgb, y_pred_xgb)\n",
    "\n",
    "print(\"\\n Detailed Performance Metrics (Test Set):\")\n",
    "print(f\"Sensitivity (Recall for High-Risk): {sensitivity:.3f}\")\n",
    "print(f\"Specificity (Recall for Low-Risk): {specificity:.3f}\")\n",
    "print(f\"Precision (High-Risk): {precision_val:.3f}\")\n",
    "print(f\"Recall (High-Risk): {recall_val:.3f}\")\n",
    "\n",
    "#  ROC Curve \n",
    "fpr, tpr, _ = roc_curve(y_test_xgb, y_proba_xgb)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"AUC = {roc_auc:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], \"--\", color=\"grey\")\n",
    "plt.xlabel(\"1 - Specificity (FPR)\")\n",
    "plt.ylabel(\"Sensitivity (TPR)\")\n",
    "plt.title(\"ROC Curve — XGBoost (HR=1)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Precision–Recall Curve \n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_test_xgb, y_proba_xgb)\n",
    "avg_prec = average_precision_score(y_test_xgb, y_proba_xgb)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(recall_vals, precision_vals, color=\"green\", lw=2, label=f\"AP = {avg_prec:.3f}\")\n",
    "plt.xlabel(\"Recall (Sensitivity)\")\n",
    "plt.ylabel(\"Precision (PPV)\")\n",
    "plt.title(\"Precision–Recall Curve — XGBoost (HR=1)\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Feature Importances\n",
    "importances = pd.Series(xgb_model.feature_importances_, index=X_train_xgb.columns)\n",
    "top20 = importances.sort_values(ascending=False).head(20)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "top20.plot(kind=\"barh\", color=\"teal\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Top 20 Feature Importances — XGBoost (HR=1)\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "top20.to_csv(\"results/top20_features_xgboost.csv\", header=[\"Importance\"])\n",
    "print(\"Top 20 features saved to results/top20_features_xgboost.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727433aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 11 — Evaluate the XGboost model \n",
    "# ============================================================\n",
    "\"\"\"\n",
    "Goal:\n",
    "1. To evaluate the internal consistency of the XGBoost model using stratified 5-fold cross-validation.\n",
    "2. Why StratifiedKFold?\n",
    "   It ensures each fold preserves the same proportion of High-risk and Low-risk samples,\n",
    "   which is crucial for imbalanced biomedical datasets.\n",
    "3. Why cross-validation here?\n",
    "   Unlike Random Forest, XGBoost does not have an OOB (Out-of-Bag) estimate.\n",
    "   Therefore, cross-validation provides a robust internal validation measure\n",
    "   to assess model stability and potential overfitting.\n",
    "\"\"\"\n",
    "\n",
    "# Cross-validation setup (5-fold, stratified)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "cv_scores = cross_val_score(\n",
    "    xgb_model, X_train_xgb, y_train_xgb,\n",
    "    cv=cv, scoring='accuracy', n_jobs=1\n",
    ")\n",
    "\n",
    "print(f\"\\nCross-Validation Accuracy: {cv_scores.mean()*100:.2f}% ± {cv_scores.std()*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3020e4a-3c78-445d-94f8-86df477b28c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Section 12 - Random forest SHAP Analysis\n",
    "# =========================================================\n",
    "\"\"\"\n",
    "Goal:\n",
    "1. Use SHAP (SHapley Additive exPlanations) to interpret RF and XGBoost predictions.\n",
    "2. Understand which VOCs and metadata features contribute most to predicting high-risk adenoma.\n",
    "Why SHAP?\n",
    "Unlike model feature importance which only tells us how imp a variable is\n",
    "SHAP also tells us in what direction each feature pushes the prediction.\n",
    "\n",
    "Outputs:\n",
    "1. Global SHAP summary plot : shows how each feature influences predictions.\n",
    "   (Red = increases high-risk probability, Blue = decreases)\n",
    "2. Bar plot → average magnitude (|SHAP|) of each feature’s effect.\n",
    "3. Ranked top SHAP-important features for reproducible reporting.\n",
    "\"\"\"\n",
    "\n",
    "# --- Reproducibility ---\n",
    "np.random.seed(42)\n",
    "\n",
    "#Prepare numeric data\n",
    "# -----------------------------\n",
    "X_train_for_shap = X_train_balanced.astype(float)\n",
    "X_test_for_shap = X_test_combined[X_train_for_shap.columns].astype(float)\n",
    "\n",
    "# Background sample for SHAP \n",
    "background = X_train_for_shap.sample(min(100, len(X_train_for_shap)), random_state=42)\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "#  RANDOM FOREST SHAP Analysis\n",
    "print(\"\\n Running SHAP for Random Forest...\")\n",
    "\n",
    "rf_classes = rf_model_combined.classes_\n",
    "print(f\"RF classes: {rf_classes}\")\n",
    "\n",
    "# Run SHAP with interventional mode\n",
    "explainer_rf = shap.TreeExplainer(\n",
    "    rf_model_combined,\n",
    "    data=background,\n",
    "    feature_perturbation=\"interventional\"\n",
    ")\n",
    "shap_values_rf = explainer_rf(X_test_for_shap)\n",
    "\n",
    "# Extract SHAP values (index 1 corresponds to class 3 = Low-risk)\n",
    "values_rf = (\n",
    "    shap_values_rf.values[:, :, 1]\n",
    "    if shap_values_rf.values.ndim == 3\n",
    "    else shap_values_rf.values\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Recoding SHAP direction so positive = High-risk (class 2).\")\n",
    "values_rf = -values_rf  # flip sign so positive = High-risk\n",
    "\n",
    "#SHAP summary plots\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(values_rf, X_test_for_shap, show=False)\n",
    "plt.title(\"Global SHAP Summary — Random Forest (HR-positive)\")\n",
    "plt.tight_layout()\n",
    "plt.show(block=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(values_rf, X_test_for_shap, plot_type=\"bar\", show=False)\n",
    "plt.title(\"Mean |SHAP| Values — Random Forest (HR-positive)\")\n",
    "plt.tight_layout()\n",
    "plt.show(block=False)\n",
    "\n",
    "# SHAP importance ranking\n",
    "shap_importance_rf = np.abs(values_rf).mean(axis=0)\n",
    "shap_ranking_rf = pd.DataFrame({\n",
    "    \"Feature\": X_test_for_shap.columns,\n",
    "    \"Mean|SHAP|\": shap_importance_rf\n",
    "}).sort_values(by=\"Mean|SHAP|\", ascending=False)\n",
    "\n",
    "shap_ranking_rf.to_csv(\"results/shap_importance_random_forest.csv\", index=False)\n",
    "print(\"\\n Top 10 SHAP-important features (Random Forest):\")\n",
    "print(shap_ranking_rf.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6320c62d-54c8-4e50-90a0-781aa359aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Section 13 - XGBOOST SHAP Analysis \n",
    "# =========================================================\n",
    "\"\"\"\n",
    "Goal:\n",
    "1. To interpret the XGBoost model predictions and identify which features (VOCs or metadata)\n",
    "drive the classification of high-risk vs. low-risk samples.\n",
    "2. Simplified setup:\n",
    "    - A callable function is passed to SHAP, it basically is a way to get the prediction without having to\n",
    "    \"go through\" the model \n",
    "    - A smaller random background sample is used to approximate feature distributions.\n",
    "This makes the computation faster, more robust, and reproducible.\n",
    "\n",
    "Outputs:\n",
    "1. Global SHAP summary plot : shows how each feature influences predictions.\n",
    "   (Red = increases high-risk probability, Blue = decreases)\n",
    "2. Bar plot → average magnitude (|SHAP|) of each feature’s effect.\n",
    "3. Ranked top SHAP-important features for reproducible reporting.\n",
    "\"\"\"\n",
    "\n",
    "# Prepare numeric data \n",
    "# Convert all predictors to float to avoid dtype issues\n",
    "\n",
    "X_train_for_shap = X_train_balanced.astype(float)\n",
    "X_test_for_shap = X_test_combined[X_train_for_shap.columns].astype(float)\n",
    "\n",
    "#Background sample for SHAP \n",
    "# use small random subset (100) of the training data used as reference baseline\n",
    "background = X_train_for_shap.sample(min(100, len(X_train_for_shap)), random_state=42)\n",
    "\n",
    "#Force model output to be callable \n",
    "# Using predict_proba ensures SHAP can call the model directly\n",
    "f = lambda X: xgb_model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Create the explainer \n",
    "explainer_xgb = shap.Explainer(f, background)\n",
    "\n",
    "#  Compute SHAP values\n",
    "print(\"Computing SHAP values, this might take a bit...\")\n",
    "shap_values_xgb = explainer_xgb(X_test_for_shap)\n",
    "\n",
    "#Plot summary\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values_xgb.values, X_test_for_shap, show=False)\n",
    "plt.title(\"Global SHAP Summary — XGBoost (safe mode)\")\n",
    "plt.tight_layout()\n",
    "plt.show(block=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values_xgb.values, X_test_for_shap, plot_type=\"bar\", show=False)\n",
    "plt.title(\"Mean |SHAP| Values — XGBoost (safe mode)\")\n",
    "plt.tight_layout()\n",
    "plt.show(block=False)\n",
    "\n",
    "# Save top features\n",
    "shap_importance_xgb = np.abs(shap_values_xgb.values).mean(axis=0)\n",
    "shap_ranking_xgb = pd.DataFrame({\n",
    "    \"Feature\": X_test_for_shap.columns,\n",
    "    \"Mean|SHAP|\": shap_importance_xgb\n",
    "}).sort_values(by=\"Mean|SHAP|\", ascending=False)\n",
    "\n",
    "shap_ranking_xgb.to_csv(\"results/shap_importance_xgboost_final.csv\", index=False)\n",
    "\n",
    "print(\"\\n Top 10 SHAP-important features (XGBoost):\")\n",
    "print(shap_ranking_xgb.head(10))\n",
    "\n",
    "print(\"\\n SHAP analysis complete (simple safe version). Results saved in 'results/' folder.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720e7d6a",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# FINAL SUMMARY — Summary of Findings — Supervised Classification (RF + XGBoost)\n",
    "# ============================================================\n",
    "\n",
    "###Random Forest\n",
    "- Accuracy on tesr: 82.9%  \n",
    "- Sensitivity/recall : HR=0.73  , LR=0.88\n",
    "- Precision : HR=0.73, LR=0.88\n",
    "- OOB Accuracy: 89.56%\n",
    "- CV Accuracy: 89.56% ± 3.58%\n",
    "- The sensitivity/specificity differences between OOB and Test suggest there is overfitting in the model which is why RF was compared to XGBoost. \n",
    "\n",
    "###XGBoost\n",
    "- Test Accuracy: 88.6%  \n",
    "- Sensitivity / Recall: High-Risk = 0.73, Low-Risk = 0.96  \n",
    "- Precision: High-Risk = 0.89, Low-Risk = 0.88  \n",
    "- ROC AUC (Test): 0.886  \n",
    "- Precision–Recall AP (Test): 0.870  \n",
    "- Interpretation: XGboost outperformed Random Forest on the external test set while maintaining strong recall for both risk groups. It uses sequential boosting and controlled learning rate which improved generalization and reduced overfitting as can be seen with the Test accuryacy = 88.7 and Cross validation accuracy 90.65% ± 5.40% (difference is much less big than for the RF)\n",
    "\n",
    "\n",
    "\n",
    "###Overall Insights\n",
    "- Both ensemble methods identified overlapping key VOCs, strengthening their biological relevance.\n",
    "- Bootstrapped upsampling effectively balanced classes and improved sensitivity to the high-risk group.\n",
    "- The RF model maintained stability across OOB and CV estimates although there is overfitting.\n",
    "\n",
    "\n",
    "###Future Work\n",
    "- Building an ensembl to combine classifiers\n",
    "- Hyperparametre tuning \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
