{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88ac60b-62bc-4433-bfe5-3f2bb5313faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 1 ‚Äî Imports and Data Loading\n",
    "# ============================================================\n",
    "\n",
    "#Note: \n",
    "#Each preprocessing and embedding section (e.g., ‚ÄúURF + PCA‚Äù, ‚ÄúBatch correction + PCA smoothing‚Äù) is implemented as an independent block to \n",
    "# allows users to run a single analysis pipeline of interest without re-executing all prior steps.  \n",
    "\n",
    "# Install required packages\n",
    "!pip install neuroCombat umap-learn --quiet\n",
    "!pip install -U scikit-learn\n",
    "\n",
    "# Core libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "#  Preprocessing & dimensionality reduction \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.impute import KNNImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import umap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from neuroCombat import neuroCombat\n",
    "# Batch correction\n",
    "from neuroCombat import neuroCombat\n",
    "from neuroCombat import neuroCombat\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# --- Imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import umap\n",
    "from sklearn.metrics import silhouette_score\n",
    "from neuroCombat import neuroCombat\n",
    "\n",
    "# Set visualization style\n",
    "sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "filename = \"path/to/your/file.xlsx \"\n",
    "\n",
    "# Load Excel file\n",
    "df = pd.read_excel(filename, engine=\"openpyxl\")\n",
    "\n",
    "print(f\"Dataset loaded successfully! Shape: {df.shape}\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72ec586-c657-49d0-aa6c-12eade4b47a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Goal:\n",
    "To prepare the dataset for unsupervised learning and visualize intrinsic structure\n",
    "between high-risk (HRA) and low-risk (LRA) adenoma samples.\n",
    "\n",
    "Approach:\n",
    "1. Clean and filter biological samples (remove blanks, standardize labels).\n",
    "2. Identify valid VOC features based on missingness (<30% per subgroup).\n",
    "3. Impute missing values using k-Nearest Neighbors (kNN) to preserve local patterns.\n",
    "4. Log-transform and correct batch effects using neuroCombat.\n",
    "5. Focus analysis on biologically relevant (top) VOCs from prior importance.\n",
    "6. Apply Unsupervised Random Forest (URF) to capture complex non-linear similarities.\n",
    "7. Visualize sample relationships with Multidimensional Scaling (MDS).\n",
    "8. Quantify group separation using the Silhouette score.\n",
    "\n",
    "Note : this is the figure that was shown in the presentation. In the following sections of this script, the code is improved.\n",
    "\"\"\"\n",
    "\n",
    "#CLEANUP AND SUBGROUP SELECTION\n",
    "# Replace \"n.a.\" etc. with NaN for consistency\n",
    "df.replace(['n.a.', 'n.a', 'N.A.', 'N./A as blank'], np.nan, inplace=True)\n",
    "\n",
    "# Keep only biological samples: High- and Low-Risk Adenoma (2 & 3)\n",
    "df_real = df[df['Study subgroup'].isin([2, 3])].copy()\n",
    "\n",
    "# Remove any rows with 'blank' in the Label column\n",
    "df_real = df_real[~df_real['Label'].str.contains('blank', case=False, na=False)]\n",
    "\n",
    "# Ensure numeric and clean subgroup column\n",
    "df_real = df_real[pd.to_numeric(df_real['Study subgroup'], errors='coerce').notna()]\n",
    "df_real['Study subgroup'] = df_real['Study subgroup'].astype(int)\n",
    "\n",
    "# Map subgroup codes to readable names\n",
    "subgroup_map = {2: 'High Risk Adenoma', 3: 'Low Risk Adenoma'}\n",
    "df_real['Group'] = df_real['Study subgroup'].map(subgroup_map)\n",
    "\n",
    "print(f\" Biological samples retained: {df_real.shape[0]}\")\n",
    "print(df_real['Group'].value_counts())\n",
    "\n",
    "#IDENTIFY VOC COLUMNS\n",
    "voc_start_col = None\n",
    "for col in df.columns:\n",
    "    if col.lower().startswith('2-pentene'):\n",
    "        voc_start_col = col\n",
    "        break\n",
    "\n",
    "if voc_start_col is None:\n",
    "    raise ValueError(\" Could not find '2-Pentene' start column in dataset!\")\n",
    "\n",
    "voc_start_idx = df.columns.get_loc(voc_start_col)\n",
    "metabolite_cols = df.columns[voc_start_idx:]\n",
    "print(f\" Identified {len(metabolite_cols)} potential VOC columns starting from: {voc_start_col}\")\n",
    "\n",
    "# Convert all VOC columns to numeric\n",
    "df[metabolite_cols] = df[metabolite_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "#FILTER VOCS BASED ON MISSINGNESS (HRA & LRA ONLY)\n",
    "final_vocs = []\n",
    "for col in metabolite_cols:\n",
    "    drop_count = 0\n",
    "    for subgroup in [2, 3]:\n",
    "        subgroup_mask = df_real['Study subgroup'] == subgroup\n",
    "        missing_pct = df_real.loc[subgroup_mask, col].isna().mean() * 100\n",
    "        if missing_pct > 30:\n",
    "            drop_count += 1\n",
    "    if drop_count <= 1:  # keep if missing in ‚â§ 1 subgroup\n",
    "        final_vocs.append(col)\n",
    "\n",
    "print(f\" VOCs kept after missingness filtering: {len(final_vocs)}\")\n",
    "\n",
    "#KNN IMPUTATION + LOG TRANSFORMATION\n",
    "X = df_real[final_vocs].copy()\n",
    "\n",
    "# Apply 3-nearest-neighbor imputation\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns, index=X.index)\n",
    "\n",
    "# Remove zero-variance features (flat signals)\n",
    "X_nonzero = X_imputed.loc[:, X_imputed.var() > 0]\n",
    "\n",
    "# Log-transform to reduce skewness\n",
    "X_log = np.log1p(X_nonzero)\n",
    "\n",
    "print(f\" Data prepared for batch correction. Shape: {X_log.shape}\")\n",
    "\n",
    "# BATCH CORRECTION WITH neuroCombat\n",
    "# ============================================================\n",
    "covars = pd.DataFrame({\n",
    "    'Batch': df_real['Seq'],\n",
    "    'Subgroup': df_real['Study subgroup']\n",
    "}, index=df_real.index)\n",
    "\n",
    "combat_result = neuroCombat(\n",
    "    dat=X_log.T,\n",
    "    covars=covars,\n",
    "    batch_col='Batch',\n",
    "    categorical_cols=['Subgroup']\n",
    ")\n",
    "\n",
    "X_combat = pd.DataFrame(\n",
    "    combat_result['data'].T,\n",
    "    index=X_log.index,\n",
    "    columns=X_log.columns\n",
    ")\n",
    "\n",
    "print(\" neuroCombat batch correction complete!\")\n",
    "\n",
    "#DEFINE MANUALLY SELECTED TOP VOCS (FROM LITERATURE OR FEATURE IMPORTANCE)\n",
    "#these are based on the RF top 20 features from the presentation, since then the code was improved but \n",
    "# the top 20 features didn't change much \n",
    "top_vocs = [\n",
    "    '4-Heptanone', '2,5-Dimethylstyrene', 'Propylene glycol', 'Valencene_Peak1',\n",
    "    '4-Ethylphenol', '2-Methoxyethanol', '1-Propanol', '3-Methylindole', 'Indole',\n",
    "    'Acetic acid', 'Dimethyl trisulfide', 'Dimethyl disulfide',\n",
    "    '4-Methyl-2(5H)-furanone', 'Bis(methylthio)methane',\n",
    "    'Diethylene glycol monoethyl ether', 'Pyridine', 'Chlorobenzene',\n",
    "    'Pyrrole-2-carboxaldehyde', '1,3,5-Triazine', '2-Heptanone'\n",
    "]\n",
    "\n",
    "# Keep only those present in the dataset\n",
    "top_vocs = [v for v in top_vocs if v in X_combat.columns]\n",
    "print(f\"Using {len(top_vocs)} top VOCs for URF analysis.\")\n",
    "X_rf = X_combat[top_vocs].copy()\n",
    "\n",
    "# STANDARD SCALING\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_rf),\n",
    "    columns=X_rf.columns,\n",
    "    index=X_rf.index\n",
    ")\n",
    "\n",
    "print(\" Data scaled for Random Forest modeling.\")\n",
    "\n",
    "\n",
    "# UNSUPERVISED RANDOM FOREST (URF) + HRA BOOTSTRAPPING\n",
    "hra_idx = df_real[df_real['Group'] == 'High Risk Adenoma'].index\n",
    "lra_idx = df_real[df_real['Group'] == 'Low Risk Adenoma'].index\n",
    "\n",
    "n_hra_needed = len(lra_idx) - len(hra_idx)\n",
    "if n_hra_needed > 0:\n",
    "    hra_bootstrap_idx = np.random.choice(hra_idx, size=n_hra_needed, replace=True)\n",
    "    X_scaled_augmented = pd.concat([X_scaled, X_scaled.loc[hra_bootstrap_idx]], axis=0)\n",
    "else:\n",
    "    X_scaled_augmented = X_scaled.copy()\n",
    "\n",
    "X_perm = X_scaled_augmented.apply(np.random.permutation, axis=0).values\n",
    "X_aug = np.vstack([X_scaled_augmented.values, X_perm])\n",
    "y_rf = np.concatenate([np.ones(X_scaled_augmented.shape[0]), np.zeros(X_perm.shape[0])])\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=4000,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X_aug, y_rf)\n",
    "print(\" Unsupervised Random Forest trained successfully.\")\n",
    "\n",
    "# PROXIMITY MATRIX COMPUTATION\n",
    "leaf_indices = rf.apply(X_aug)\n",
    "leaf_real = leaf_indices[:X_scaled_augmented.shape[0]]\n",
    "\n",
    "# Compute proximity matrix only for original samples\n",
    "n_samples = X_scaled.shape[0]\n",
    "proximity = np.mean(\n",
    "    leaf_real[:n_samples, None, :] == leaf_real[:n_samples, None, :].transpose(1, 0, 2),\n",
    "    axis=2\n",
    ")\n",
    "\n",
    "print(\" Proximity matrix computed.\")\n",
    "\n",
    "#MDS EMBEDDING + VISUALIZATION\n",
    "mds = MDS(n_components=2, dissimilarity='precomputed', random_state=42)\n",
    "embedding = mds.fit_transform(1 - proximity)\n",
    "df_real['URF_PC1'] = embedding[:, 0]\n",
    "df_real['URF_PC2'] = embedding[:, 1]\n",
    "\n",
    "# Compute Silhouette Score (HRA vs LRA)\n",
    "X_emb = df_real[['URF_PC1', 'URF_PC2']].values\n",
    "labels = df_real['Group'].values\n",
    "sil_score = silhouette_score(X_emb, labels)\n",
    "print(f\" Silhouette score (HRA vs LRA): {sil_score:.3f}\")\n",
    "\n",
    "#  Visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    x='URF_PC1', y='URF_PC2',\n",
    "    hue='Group',\n",
    "    data=df_real,\n",
    "    palette='Set2',\n",
    "    s=80,\n",
    "    edgecolor='black',\n",
    "    alpha=0.85\n",
    ")\n",
    "plt.title('URF‚ÄìMDS of VOC Profiles (HRA vs LRA)', fontsize=14)\n",
    "plt.xlabel('URF Dimension 1')\n",
    "plt.ylabel('URF Dimension 2')\n",
    "plt.legend(title='Group', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa89e8a-17c0-4e0b-86be-7a6898c67244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 1 ‚Äî Baseline: Raw Data Processing & uRF‚ÄìUMAP (No Batch Correction)\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "Goal:\n",
    "To establish a baseline unsupervised structure of the dataset\n",
    "( before any batch correction or normalization).\n",
    "We use an Unsupervised Random Forest (uRF) + UMAP embedding\n",
    "to visualize whether High-Risk (HRA) and Low-Risk (LRA) adenoma\n",
    "samples show any natural separation.\n",
    "\n",
    "This baseline view helps reveal whether technical or biological\n",
    "factors dominate the variance in VOC profiles and sets the stage\n",
    "for comparing pre- and post-batch correction structures.\n",
    "\"\"\"\n",
    "\n",
    "#Load Excel file\n",
    "filename = \"path/to/your/file.xlsx \"\n",
    "na_labels = [\"n.a.\", \"N.A.\", \"NA\", \"Na\", \"na\", \"NaN\", \"\", \" \"]\n",
    "\n",
    "\n",
    "df = pd.read_excel(filename, engine=\"openpyxl\", na_values=na_labels)\n",
    "\n",
    "print(f\" Loaded file: {filename}, shape = {df.shape}\")\n",
    "\n",
    "\n",
    "# Clean blanks & subgroup labels \n",
    "df.loc[df[\"Label\"] == \"EquipmentBlank\", \"Study subgroup\"] = 0\n",
    "df.loc[df[\"Label\"] == \"AmbientBlank\", \"Study subgroup\"] = 1\n",
    "df = df[df[\"Study subgroup\"] != \"NOT FOUND\"]\n",
    "df[\"Study subgroup\"] = pd.to_numeric(df[\"Study subgroup\"], errors=\"coerce\")\n",
    "\n",
    "# Identify VOC columns \n",
    "voc_start_col = df.columns.get_loc(\"2-Pentene, (Z)\")\n",
    "voc_cols = df.columns[voc_start_col:]\n",
    "df[voc_cols] = df[voc_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# Keep only real biological samples (2 = HRA, 3 = LRA)\n",
    "df_real = df[df[\"Study subgroup\"].isin([2, 3])].copy()\n",
    "df_blanks = df[df[\"Study subgroup\"].isin([0, 1])].copy()\n",
    "\n",
    "subgroup_map = {2: \"High Risk Adenoma\", 3: \"Low Risk Adenoma\"}\n",
    "df_real[\"Group\"] = df_real[\"Study subgroup\"].map(subgroup_map)\n",
    "\n",
    "# Missingness filtering + median imputation (per subgroup)\n",
    "threshold = 30  # % missing allowed\n",
    "cols_to_keep = []\n",
    "\n",
    "for col in voc_cols:\n",
    "    pct2 = df_real.loc[df_real[\"Study subgroup\"] == 2, col].isna().mean() * 100\n",
    "    pct3 = df_real.loc[df_real[\"Study subgroup\"] == 3, col].isna().mean() * 100\n",
    "    if pct2 > threshold and pct3 > threshold:\n",
    "        continue\n",
    "    cols_to_keep.append(col)\n",
    "    \n",
    "    med2 = df_real.loc[df_real[\"Study subgroup\"] == 2, col].median()\n",
    "    med3 = df_real.loc[df_real[\"Study subgroup\"] == 3, col].median()\n",
    "    df_real.loc[df_real[\"Study subgroup\"] == 2, col] = df_real.loc[df_real[\"Study subgroup\"] == 2, col].fillna(med2 if not np.isnan(med2) else med3)\n",
    "    df_real.loc[df_real[\"Study subgroup\"] == 3, col] = df_real.loc[df_real[\"Study subgroup\"] == 3, col].fillna(med3 if not np.isnan(med3) else med2)\n",
    "\n",
    "print(f\" VOCs kept after missingness filter: {len(cols_to_keep)}\")\n",
    "\n",
    "# Mann‚ÄìWhitney U test (real samples vs blanks) \n",
    "significant_vocs = []\n",
    "for col in cols_to_keep:\n",
    "    real_vals = df_real[col].dropna()\n",
    "    blank_vals = df_blanks[col].dropna()\n",
    "    if len(real_vals) > 2 and len(blank_vals) > 2:\n",
    "        stat, pval = mannwhitneyu(real_vals, blank_vals, alternative=\"two-sided\")\n",
    "        if pval < 0.05:\n",
    "            significant_vocs.append(col)\n",
    "\n",
    "print(f\"Kept {len(significant_vocs)} significant VOCs after blank filtering.\")\n",
    "\n",
    "#Unsupervised Random Forest (uRF) \n",
    "X = df_real[significant_vocs].copy()\n",
    "X_real = X.values\n",
    "np.random.seed(42)\n",
    "X_perm = np.random.permutation(X_real)\n",
    "y_unsup = np.concatenate([np.ones(len(X_real)), np.zeros(len(X_perm))])\n",
    "X_unsup = np.vstack([X_real, X_perm])\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=1000,\n",
    "    max_features=\"sqrt\",\n",
    "    min_samples_leaf=2,\n",
    "    n_jobs=1,\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X_unsup, y_unsup)\n",
    "\n",
    "# Compute proximity matrix\n",
    "leaf_indices = rf.apply(X_real)\n",
    "n_trees = leaf_indices.shape[1]\n",
    "n_samples = leaf_indices.shape[0]\n",
    "proximity = np.zeros((n_samples, n_samples))\n",
    "\n",
    "for tree in range(n_trees):\n",
    "    leaves = leaf_indices[:, tree]\n",
    "    for leaf in np.unique(leaves):\n",
    "        idx = np.where(leaves == leaf)[0]\n",
    "        proximity[np.ix_(idx, idx)] += 1\n",
    "proximity /= n_trees\n",
    "\n",
    "#UMAP embedding\n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.1,\n",
    "    metric=\"precomputed\",\n",
    "    random_state=42\n",
    ")\n",
    "embedding = reducer.fit_transform(1 - proximity)\n",
    "df_real[\"uRF_UMAP1\"] = embedding[:, 0]\n",
    "df_real[\"uRF_UMAP2\"] = embedding[:, 1]\n",
    "\n",
    "# Visualize baseline (no correction) \n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "sns.scatterplot(data=df_real, x=\"uRF_UMAP1\", y=\"uRF_UMAP2\",\n",
    "                hue=\"Group\", palette=\"Set2\", s=80, edgecolor=\"black\", ax=axes[0])\n",
    "axes[0].set_title(\"Baseline uRF‚ÄìUMAP (Biological Groups)\")\n",
    "\n",
    "sns.scatterplot(data=df_real, x=\"uRF_UMAP1\", y=\"uRF_UMAP2\",\n",
    "                hue=\"Seq\", palette=\"tab20\", s=80, edgecolor=\"black\", ax=axes[1])\n",
    "axes[1].set_title(\"Baseline uRF‚ÄìUMAP (Colored by Batch)\")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cbdedd-ead0-48cf-b4cc-2261acd9fc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Batch Correction & uRF‚ÄìUMAP (After ComBat)\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "Goal:\n",
    "To visualize how batch correction (using ComBat) alters the structure of VOC data,\n",
    "and to check whether biological differences (HRA vs LRA) are preserved after\n",
    "removing technical batch effects.\n",
    "\n",
    "Why this step?\n",
    "In the baseline UMAP, sample separation may have reflected sequencing or instrument\n",
    "batch differences (technical variation). Here, we correct for those effects using\n",
    "the neuroCombat algorithm while preserving biological subgroup variation.\n",
    "\"\"\"\n",
    "\n",
    "# Standardize before ComBat \n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X),\n",
    "    index=X.index,\n",
    "    columns=X.columns\n",
    ")\n",
    "\n",
    "# Define covariates \n",
    "covars = pd.DataFrame({\n",
    "    \"Batch\": df_real[\"Seq\"],\n",
    "    \"Subgroup\": df_real[\"Study subgroup\"]\n",
    "}, index=df_real.index)\n",
    "\n",
    "#  Run ComBat with scaling \n",
    "combat_result = neuroCombat(\n",
    "    dat=X_scaled.T,\n",
    "    covars=covars,\n",
    "    batch_col=\"Batch\",\n",
    "    categorical_cols=[\"Subgroup\"]\n",
    ")\n",
    "X_combat = pd.DataFrame(combat_result[\"data\"].T, index=X.index, columns=X.columns)\n",
    "print(\" ComBat (scaled) complete!\")\n",
    "\n",
    "# Continue with URF + UMAP \n",
    "X_real = X_combat.values\n",
    "X_perm = np.random.permutation(X_real)\n",
    "y_unsup = np.concatenate([np.ones(len(X_real)), np.zeros(len(X_perm))])\n",
    "X_unsup = np.vstack([X_real, X_perm])\n",
    "\n",
    "rf.fit(X_unsup, y_unsup)\n",
    "\n",
    "leaf_indices = rf.apply(X_real)\n",
    "n_trees = leaf_indices.shape[1]\n",
    "n_samples = leaf_indices.shape[0]\n",
    "proximity = np.zeros((n_samples, n_samples))\n",
    "\n",
    "for tree in range(n_trees):\n",
    "    leaves = leaf_indices[:, tree]\n",
    "    for leaf in np.unique(leaves):\n",
    "        idx = np.where(leaves == leaf)[0]\n",
    "        proximity[np.ix_(idx, idx)] += 1\n",
    "proximity /= n_trees\n",
    "\n",
    "# UMAP \n",
    "import umap\n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.1,\n",
    "    metric=\"precomputed\",\n",
    "    random_state=42\n",
    ")\n",
    "embedding = reducer.fit_transform(1 - proximity)\n",
    "df_real[\"uRF_UMAP1\"] = embedding[:, 0]\n",
    "df_real[\"uRF_UMAP2\"] = embedding[:, 1]\n",
    "\n",
    "#Plot 1: by subgroup\n",
    "sns.scatterplot(\n",
    "    data=df_real, x=\"uRF_UMAP1\", y=\"uRF_UMAP2\",\n",
    "    hue=\"Group\", palette=\"Set2\", s=80, edgecolor=\"black\", alpha=0.9\n",
    ")\n",
    "plt.title(\"uRF‚ÄìUMAP after Scaled ComBat (Biological Groups)\")\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: by batch\n",
    "sns.scatterplot(\n",
    "    data=df_real, x=\"uRF_UMAP1\", y=\"uRF_UMAP2\",\n",
    "    hue=\"Seq\", palette=\"tab20\", s=80, edgecolor=\"black\", alpha=0.9\n",
    ")\n",
    "plt.title(\"uRF‚ÄìUMAP after Scaled ComBat (Colored by Batch)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2539e7-4440-4ed7-9d8b-79e2ccb469d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 3 ‚Äî Scaled ComBat + PCA Smoothing + uRF‚ÄìUMAP\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "Goal:\n",
    "To refine the batch-corrected dataset by applying PCA smoothing\n",
    "before running the unsupervised Random Forest (uRF) and UMAP visualization.\n",
    "\n",
    "Why add PCA?\n",
    "After ComBat correction, some residual noise and feature-level variance\n",
    "may remain. PCA helps to:\n",
    "  - Denoise the data by capturing only the dominant variance components,\n",
    "  - Reduce dimensionality (simplify highly correlated VOC space),\n",
    "  - Stabilize the uRF proximity computation (less random variability).\n",
    "\n",
    "This version focuses on overall structure rather than individual VOC-level noise.\n",
    "\"\"\"\n",
    "\n",
    "#  Full (scaled) ComBat correction \n",
    "covars = pd.DataFrame({\n",
    "    \"Batch\": df_real[\"Seq\"],\n",
    "    \"Subgroup\": df_real[\"Study subgroup\"]\n",
    "}, index=df_real.index)\n",
    "\n",
    "combat_result = neuroCombat(\n",
    "    dat=X_scaled.T,\n",
    "    covars=covars,\n",
    "    batch_col=\"Batch\",\n",
    "    categorical_cols=[\"Subgroup\"]\n",
    ")\n",
    "X_combat = pd.DataFrame(combat_result[\"data\"].T, index=X_scaled.index, columns=X_scaled.columns)\n",
    "\n",
    "# PCA smoothing \n",
    "pca = PCA(n_components=50, random_state=42)\n",
    "X_pca = pca.fit_transform(X_combat)\n",
    "\n",
    "#  uRF as before \n",
    "X_real = X_pca\n",
    "X_perm = np.random.permutation(X_real)\n",
    "y_unsup = np.concatenate([np.ones(len(X_real)), np.zeros(len(X_perm))])\n",
    "X_unsup = np.vstack([X_real, X_perm])\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=1000,\n",
    "    max_features=\"sqrt\",\n",
    "    min_samples_leaf=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X_unsup, y_unsup)\n",
    "\n",
    "leaf_indices = rf.apply(X_real)\n",
    "n_trees = leaf_indices.shape[1]\n",
    "n_samples = leaf_indices.shape[0]\n",
    "proximity = np.zeros((n_samples, n_samples))\n",
    "for tree in range(n_trees):\n",
    "    leaves = leaf_indices[:, tree]\n",
    "    for leaf in np.unique(leaves):\n",
    "        idx = np.where(leaves == leaf)[0]\n",
    "        proximity[np.ix_(idx, idx)] += 1\n",
    "proximity /= n_trees\n",
    "\n",
    "# UMAP embedding \n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.1,\n",
    "    metric=\"precomputed\",\n",
    "    random_state=42\n",
    ")\n",
    "embedding = reducer.fit_transform(1 - proximity)\n",
    "df_real[\"uRF_UMAP1\"], df_real[\"uRF_UMAP2\"] = embedding[:,0], embedding[:,1]\n",
    "\n",
    "# --- Plots ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "sns.scatterplot(data=df_real, x=\"uRF_UMAP1\", y=\"uRF_UMAP2\",\n",
    "                hue=\"Group\", palette=\"Set2\", s=80, edgecolor=\"black\", ax=axes[0])\n",
    "axes[0].set_title(\"uRF‚ÄìUMAP after Scaled ComBat + PCA (Groups)\")\n",
    "\n",
    "sns.scatterplot(data=df_real, x=\"uRF_UMAP1\", y=\"uRF_UMAP2\",\n",
    "                hue=\"Seq\", palette=\"tab20\", s=80, edgecolor=\"black\", ax=axes[1])\n",
    "axes[1].set_title(\"uRF‚ÄìUMAP after Scaled ComBat + PCA (Batches)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf9690-3a21-43f9-8b5a-0a08f8793bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üß© FINAL SECTION ‚Äî Scaled ComBat + PCA + Z-score + uRF‚ÄìUMAP\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "Goal:\n",
    "To produce the final unsupervised embedding of the dataset after\n",
    "complete preprocessing ‚Äî scaling, batch correction, denoising (PCA),\n",
    "and normalization ‚Äî using an Unsupervised Random Forest (uRF) followed\n",
    "by UMAP visualization.\n",
    "\n",
    "This version aims for the most balanced tradeoff between:\n",
    "biological signal preservation, batch effect removal, noise reduction and interpretability\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#Standardize raw data \n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X),\n",
    "    index=X.index,\n",
    "    columns=X.columns\n",
    ")\n",
    "\n",
    "#Prepare covariates for ComBat \n",
    "covars = pd.DataFrame({\n",
    "    \"Batch\": df_real[\"Seq\"],                # batch column\n",
    "    \"Subgroup\": df_real[\"Study subgroup\"]   # biological variable\n",
    "}, index=df_real.index)\n",
    "\n",
    "#Scaled ComBat batch correction \n",
    "combat_result = neuroCombat(\n",
    "    dat=X_scaled.T,\n",
    "    covars=covars,\n",
    "    batch_col=\"Batch\",\n",
    "    categorical_cols=[\"Subgroup\"]\n",
    ")\n",
    "X_combat = pd.DataFrame(\n",
    "    combat_result[\"data\"].T,\n",
    "    index=X_scaled.index,\n",
    "    columns=X_scaled.columns\n",
    ")\n",
    "print(\" Scaled ComBat correction complete!\")\n",
    "\n",
    "# PCA smoothing \n",
    "pca = PCA(n_components=50, random_state=42)\n",
    "X_pca = pca.fit_transform(X_combat)\n",
    "print(\"PCA smoothing complete!\")\n",
    "\n",
    "# Post-ComBat z-score normalization \n",
    "scaler2 = StandardScaler()\n",
    "X_z = scaler2.fit_transform(X_pca)\n",
    "print(\"Global z-score normalization complete!\")\n",
    "\n",
    "# Unsupervised Random Forest \n",
    "X_real = X_z\n",
    "X_perm = np.random.permutation(X_real)\n",
    "y_unsup = np.concatenate([\n",
    "    np.ones(len(X_real)),\n",
    "    np.zeros(len(X_perm))\n",
    "])\n",
    "X_unsup = np.vstack([X_real, X_perm])\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=1000,\n",
    "    max_features=\"sqrt\",\n",
    "    min_samples_leaf=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X_unsup, y_unsup)\n",
    "print(\"Random forest trained for uRF proximity.\")\n",
    "\n",
    "# Compute proximity matrix \n",
    "leaf_indices = rf.apply(X_real)\n",
    "n_trees = leaf_indices.shape[1]\n",
    "n_samples = leaf_indices.shape[0]\n",
    "proximity = np.zeros((n_samples, n_samples))\n",
    "for tree in range(n_trees):\n",
    "    leaves = leaf_indices[:, tree]\n",
    "    for leaf in np.unique(leaves):\n",
    "        idx = np.where(leaves == leaf)[0]\n",
    "        proximity[np.ix_(idx, idx)] += 1\n",
    "proximity /= n_trees\n",
    "print(\"Proximity matrix computed.\")\n",
    "\n",
    "# UMAP embedding \n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.1,\n",
    "    metric=\"precomputed\",\n",
    "    random_state=42\n",
    ")\n",
    "embedding = reducer.fit_transform(1 - proximity)\n",
    "df_real[\"uRF_UMAP1\"] = embedding[:, 0]\n",
    "df_real[\"uRF_UMAP2\"] = embedding[:, 1]\n",
    "print(\"UMAP embedding complete!\")\n",
    "\n",
    "#  Visualization \n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_real, x=\"uRF_UMAP1\", y=\"uRF_UMAP2\",\n",
    "    hue=\"Group\", palette=\"Set2\", s=80,\n",
    "    edgecolor=\"black\", ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"uRF‚ÄìUMAP after ComBat + PCA + Z-score (Groups)\")\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_real, x=\"uRF_UMAP1\", y=\"uRF_UMAP2\",\n",
    "    hue=\"Seq\", palette=\"tab20\", s=80,\n",
    "    edgecolor=\"black\", ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"uRF‚ÄìUMAP after ComBat + PCA + Z-score (Batches)\")\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Silhouette check (optional)\n",
    "sil_group = silhouette_score(df_real[[\"uRF_UMAP1\", \"uRF_UMAP2\"]], df_real[\"Group\"])\n",
    "sil_batch = silhouette_score(df_real[[\"uRF_UMAP1\", \"uRF_UMAP2\"]], df_real[\"Seq\"])\n",
    "print(f\"Silhouette (Group): {sil_group:.3f}  |  Silhouette (Batch): {sil_batch:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79eb6a3",
   "metadata": {},
   "source": [
    "###Final Interpretation\n",
    "Among all tested unsupervised pipelines, the Scaled ComBat + PCA + Z-score + uRF‚ÄìUMAP configuration achieved the most balanced tradeoff between:\n",
    "- Preserving biological structure (subgroup separation)\n",
    "- Minimizing batch effects\n",
    "- Reducing noise while maintaining interpretability  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
